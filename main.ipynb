{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York City Taxi Fare Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "df = pl.read_csv(\"../../datasets/new-york-city-taxi-fare-prediction/train.csv\", n_rows=1_000_000)\n",
    "# 52.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pl.read_csv(\"../../datasets/new-york-city-taxi-fare-prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>key</th><th>fare_amount</th><th>pickup_datetime</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>passenger_count</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2009-06-15 17:26:21.0000001&quot;</td><td>4.5</td><td>&quot;2009-06-15 17:26:21 UTC&quot;</td><td>-73.844311</td><td>40.721319</td><td>-73.84161</td><td>40.712278</td><td>1</td></tr><tr><td>&quot;2010-01-05 16:52:16.0000002&quot;</td><td>16.9</td><td>&quot;2010-01-05 16:52:16 UTC&quot;</td><td>-74.016048</td><td>40.711303</td><td>-73.979268</td><td>40.782004</td><td>1</td></tr><tr><td>&quot;2011-08-18 00:35:00.00000049&quot;</td><td>5.7</td><td>&quot;2011-08-18 00:35:00 UTC&quot;</td><td>-73.982738</td><td>40.76127</td><td>-73.991242</td><td>40.750562</td><td>2</td></tr><tr><td>&quot;2012-04-21 04:30:42.0000001&quot;</td><td>7.7</td><td>&quot;2012-04-21 04:30:42 UTC&quot;</td><td>-73.98713</td><td>40.733143</td><td>-73.991567</td><td>40.758092</td><td>1</td></tr><tr><td>&quot;2010-03-09 07:51:00.000000135&quot;</td><td>5.3</td><td>&quot;2010-03-09 07:51:00 UTC&quot;</td><td>-73.968095</td><td>40.768008</td><td>-73.956655</td><td>40.783762</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ key        ┆ fare_amoun ┆ pickup_dat ┆ pickup_lo ┆ pickup_la ┆ dropoff_l ┆ dropoff_l ┆ passenger │\n",
       "│ ---        ┆ t          ┆ etime      ┆ ngitude   ┆ titude    ┆ ongitude  ┆ atitude   ┆ _count    │\n",
       "│ str        ┆ ---        ┆ ---        ┆ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆ f64        ┆ str        ┆ f64       ┆ f64       ┆ f64       ┆ f64       ┆ i64       │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2009-06-15 ┆ 4.5        ┆ 2009-06-15 ┆ -73.84431 ┆ 40.721319 ┆ -73.84161 ┆ 40.712278 ┆ 1         │\n",
       "│ 17:26:21.0 ┆            ┆ 17:26:21   ┆ 1         ┆           ┆           ┆           ┆           │\n",
       "│ 000001     ┆            ┆ UTC        ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-01-05 ┆ 16.9       ┆ 2010-01-05 ┆ -74.01604 ┆ 40.711303 ┆ -73.97926 ┆ 40.782004 ┆ 1         │\n",
       "│ 16:52:16.0 ┆            ┆ 16:52:16   ┆ 8         ┆           ┆ 8         ┆           ┆           │\n",
       "│ 000002     ┆            ┆ UTC        ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2011-08-18 ┆ 5.7        ┆ 2011-08-18 ┆ -73.98273 ┆ 40.76127  ┆ -73.99124 ┆ 40.750562 ┆ 2         │\n",
       "│ 00:35:00.0 ┆            ┆ 00:35:00   ┆ 8         ┆           ┆ 2         ┆           ┆           │\n",
       "│ 0000049    ┆            ┆ UTC        ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2012-04-21 ┆ 7.7        ┆ 2012-04-21 ┆ -73.98713 ┆ 40.733143 ┆ -73.99156 ┆ 40.758092 ┆ 1         │\n",
       "│ 04:30:42.0 ┆            ┆ 04:30:42   ┆           ┆           ┆ 7         ┆           ┆           │\n",
       "│ 000001     ┆            ┆ UTC        ┆           ┆           ┆           ┆           ┆           │\n",
       "│ 2010-03-09 ┆ 5.3        ┆ 2010-03-09 ┆ -73.96809 ┆ 40.768008 ┆ -73.95665 ┆ 40.783762 ┆ 1         │\n",
       "│ 07:51:00.0 ┆            ┆ 07:51:00   ┆ 5         ┆           ┆ 5         ┆           ┆           │\n",
       "│ 00000135   ┆            ┆ UTC        ┆           ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>key</th><th>fare_amount</th><th>pickup_datetime</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>passenger_count</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;1000000&quot;</td><td>1e6</td><td>&quot;1000000&quot;</td><td>1e6</td><td>1e6</td><td>999990.0</td><td>999990.0</td><td>1e6</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>10.0</td><td>10.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>11.348079</td><td>null</td><td>-72.52664</td><td>39.929008</td><td>-72.52786</td><td>39.919954</td><td>1.684924</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>9.82209</td><td>null</td><td>12.057937</td><td>7.626154</td><td>11.324494</td><td>8.201418</td><td>1.323911</td></tr><tr><td>&quot;min&quot;</td><td>&quot;2009-01-01 00:00:46.0000002&quot;</td><td>-44.9</td><td>&quot;2009-01-01 00:00:46 UTC&quot;</td><td>-3377.680935</td><td>-3116.285383</td><td>-3383.296608</td><td>-3114.338567</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>6.0</td><td>null</td><td>-73.99206</td><td>40.734965</td><td>-73.991385</td><td>40.734046</td><td>1.0</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>8.5</td><td>null</td><td>-73.981792</td><td>40.752695</td><td>-73.980135</td><td>40.753166</td><td>1.0</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>12.5</td><td>null</td><td>-73.967094</td><td>40.767154</td><td>-73.963654</td><td>40.768129</td><td>2.0</td></tr><tr><td>&quot;max&quot;</td><td>&quot;2015-06-30 23:53:49.0000003&quot;</td><td>500.0</td><td>&quot;2015-06-30 23:53:49 UTC&quot;</td><td>2522.271325</td><td>2621.62843</td><td>45.581619</td><td>1651.553433</td><td>208.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ key       ┆ fare_amou ┆ pickup_da ┆ … ┆ pickup_la ┆ dropoff_l ┆ dropoff_l ┆ passenge │\n",
       "│ ---       ┆ ---       ┆ nt        ┆ tetime    ┆   ┆ titude    ┆ ongitude  ┆ atitude   ┆ r_count  │\n",
       "│ str       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆ f64       ┆ str       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 1000000   ┆ 1e6       ┆ 1000000   ┆ … ┆ 1e6       ┆ 999990.0  ┆ 999990.0  ┆ 1e6      │\n",
       "│ null_coun ┆ 0         ┆ 0.0       ┆ 0         ┆ … ┆ 0.0       ┆ 10.0      ┆ 10.0      ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ null      ┆ 11.348079 ┆ null      ┆ … ┆ 39.929008 ┆ -72.52786 ┆ 39.919954 ┆ 1.684924 │\n",
       "│ std       ┆ null      ┆ 9.82209   ┆ null      ┆ … ┆ 7.626154  ┆ 11.324494 ┆ 8.201418  ┆ 1.323911 │\n",
       "│ min       ┆ 2009-01-0 ┆ -44.9     ┆ 2009-01-0 ┆ … ┆ -3116.285 ┆ -3383.296 ┆ -3114.338 ┆ 0.0      │\n",
       "│           ┆ 1 00:00:4 ┆           ┆ 1         ┆   ┆ 383       ┆ 608       ┆ 567       ┆          │\n",
       "│           ┆ 6.0000002 ┆           ┆ 00:00:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ UTC       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 25%       ┆ null      ┆ 6.0       ┆ null      ┆ … ┆ 40.734965 ┆ -73.99138 ┆ 40.734046 ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ 5         ┆           ┆          │\n",
       "│ 50%       ┆ null      ┆ 8.5       ┆ null      ┆ … ┆ 40.752695 ┆ -73.98013 ┆ 40.753166 ┆ 1.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ 5         ┆           ┆          │\n",
       "│ 75%       ┆ null      ┆ 12.5      ┆ null      ┆ … ┆ 40.767154 ┆ -73.96365 ┆ 40.768129 ┆ 2.0      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ 4         ┆           ┆          │\n",
       "│ max       ┆ 2015-06-3 ┆ 500.0     ┆ 2015-06-3 ┆ … ┆ 2621.6284 ┆ 45.581619 ┆ 1651.5534 ┆ 208.0    │\n",
       "│           ┆ 0 23:53:4 ┆           ┆ 0         ┆   ┆ 3         ┆           ┆ 33        ┆          │\n",
       "│           ┆ 9.0000003 ┆           ┆ 23:53:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ UTC       ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop un-useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key',\n",
       " 'fare_amount',\n",
       " 'pickup_datetime',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'passenger_count']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time columns from \"pickup_datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time columns from \"pickup_datetime\"\n",
    "# Day of month, Month of year, hour of day, and convert then to INTs\n",
    "\n",
    "if \"pickup_datetime\" in df.columns:\n",
    "\tdf = df.with_columns(\n",
    "\t\t[\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(8, 2).cast(pl.Int32).alias(\"day\"),\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(5, 2).cast(pl.Int32).alias(\"month\"),\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(11, 2).cast(pl.Int32).alias(\"hour\"),\n",
    "\t\t]\n",
    "\t)\n",
    "\tdf = df.drop(\"pickup_datetime\")\n",
    "\n",
    "if \"pickup_datetime\" in test.columns:\n",
    "\ttest = test.with_columns(\n",
    "\t\t[\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(8, 2).cast(pl.Int32).alias(\"day\"),\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(5, 2).cast(pl.Int32).alias(\"month\"),\n",
    "\t\t\tpl.col(\"pickup_datetime\").str.slice(11, 2).cast(pl.Int32).alias(\"hour\"),\n",
    "\t\t]\n",
    "\t)\n",
    "\ttest = test.drop(\"pickup_datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>key</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>passenger_count</th><th>day</th><th>month</th><th>hour</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;2015-01-27 13:08:24.0000002&quot;</td><td>-73.97332</td><td>40.763805</td><td>-73.98143</td><td>40.743835</td><td>1</td><td>27</td><td>1</td><td>13</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 9)\n",
       "┌──────────────┬──────────────┬──────────────┬──────────────┬───┬─────────────┬─────┬───────┬──────┐\n",
       "│ key          ┆ pickup_longi ┆ pickup_latit ┆ dropoff_long ┆ … ┆ passenger_c ┆ day ┆ month ┆ hour │\n",
       "│ ---          ┆ tude         ┆ ude          ┆ itude        ┆   ┆ ount        ┆ --- ┆ ---   ┆ ---  │\n",
       "│ str          ┆ ---          ┆ ---          ┆ ---          ┆   ┆ ---         ┆ i32 ┆ i32   ┆ i32  │\n",
       "│              ┆ f64          ┆ f64          ┆ f64          ┆   ┆ i64         ┆     ┆       ┆      │\n",
       "╞══════════════╪══════════════╪══════════════╪══════════════╪═══╪═════════════╪═════╪═══════╪══════╡\n",
       "│ 2015-01-27   ┆ -73.97332    ┆ 40.763805    ┆ -73.98143    ┆ … ┆ 1           ┆ 27  ┆ 1     ┆ 13   │\n",
       "│ 13:08:24.000 ┆              ┆              ┆              ┆   ┆             ┆     ┆       ┆      │\n",
       "│ 0002         ┆              ┆              ┆              ┆   ┆             ┆     ┆       ┆      │\n",
       "└──────────────┴──────────────┴──────────────┴──────────────┴───┴─────────────┴─────┴───────┴──────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 14:46:03.343741: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-19 14:46:03.357210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-19 14:46:03.360830: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-19 14:46:03.371367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 14:46:04.145148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values (Polars)\n",
    "df = df.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"key\", \"fare_amount\"]).to_numpy()\n",
    "y = df[\"fare_amount\"].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).sum())  # Check for NaNs in features\n",
    "print(np.isnan(y_train).sum())  # Check for NaNs in target\n",
    "\n",
    "print(np.isinf(X_train).sum())  # Check for infinities in features\n",
    "print(np.isinf(y_train).sum())  # Check for infinities in target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726749965.689893   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.714539   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.714658   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.717485   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.717628   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.717686   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.904110   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726749965.904338   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-19 14:46:05.904377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1726749965.904588   16257 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-19 14:46:05.904628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    n_cols = X_train.shape[1]\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 36.76386642456055, Val Loss: 161.05006408691406\n",
      "Epoch: 10, Loss: 39.82878494262695, Val Loss: 193.03878784179688\n",
      "Epoch: 20, Loss: 38.46057891845703, Val Loss: 1384.248291015625\n",
      "Epoch: 30, Loss: 37.15626525878906, Val Loss: 186.79763793945312\n",
      "Epoch: 40, Loss: 37.25606155395508, Val Loss: 226.6927490234375\n",
      "Epoch: 50, Loss: 37.330047607421875, Val Loss: 380.3210144042969\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class EpochLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss: {logs['loss']}, Val Loss: {logs['val_loss']}\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=50, verbose=1, restore_best_weights=True)\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "\t\t\tepochs=300,\n",
    "   \t\t\tbatch_size=4096,\n",
    "      \t\tvalidation_split=0.2,\n",
    "\t\t\tcallbacks=[early_stopping, epoch_logger],\n",
    "\t\t\tverbose=0)\n",
    "\n",
    "\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "MSE: 597.4277367138501\n",
      "MAE: 23.42888110469049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pl.DataFrame(\n",
    "\t{\n",
    "\t\t\"key\": test[\"key\"],\n",
    "\t\t\"fare_amount\": model.predict(test.drop([\"key\"]).to_numpy()).flatten(),\n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.write_csv(\"predicted_fare_amounts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
